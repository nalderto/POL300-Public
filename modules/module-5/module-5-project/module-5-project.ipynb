{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0rc2"
    },
    "colab": {
      "name": "module-5-project.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalderto/POL300-Public/blob/master/modules/module-5/module-5-project/module-5-project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QWQteKbVDrq"
      },
      "source": [
        "# Module 5 Project\n",
        "\n",
        "In this project, you will be conducting textual analysis on a state of the state address for your assigned state.  Reference [this document](https://github.com/nalderto/POL300-Public/blob/master/2020-state-of-the-state-websites.md) to find your assinged state.  The number next to each state corresponds with your assigned number.  For example, 1s are assigned to Alabama, 2s are assigned to Alaska, etc.  Simply click on the link for your respective state, and it will redirect you to the appropriate website that contains that state's 2020 state of the state address.  \n",
        "\n",
        "The general steps you will need to take in this project are the following:\n",
        "1. Use the Requests module to download the HTML file for the website that hosts your respective state's 2020 state of the state address. (See Module 3 - Obtaining the Web Page)\n",
        "1. Create an instance of the Beautiful Soup module where you pass in the content from the web page (obtained with the Requests module).  Additionally, use `'lxml'` as your HTML parser.  (See Module 3 - Using Beautiful Soup)\n",
        "1. Use Google Chrome's DevTools to find the HTML tag that encompasses the transcript text.  It is okay if there is some extra non-transcript text included, just try your best to find the HTML tag that included most of the speech text and limited amounts of other content.  (See Module 3 - Finding the Portion of the Web page for Extraction)\n",
        "1. Use the `.find` or `.findAll` functions from Beautiful Soup to obtain the proper section of the website using the HTML tags found in the previous step. (Module 3 - Using Beautiful Soup)\n",
        "1. Before you conduct text analysis, you need to remove the HTML tags from the transcript obtained the the previous step.  If the variable created in the previous step was called `transcript_html` and we wanted to created a variable called `transcript_text`, we would type `transcript_text = transcript_html.text`.  Essentially we add `.text` to the end of the variable from step 5.  **This step is super important, as your results will be wrong if we don't remove the HTML tags.**\n",
        "1. Create a dictionary called `sots` (state of the state).  In this dictionary, create a key called `State` and set it equal to your assigned state (e.g. Indiana).  Additionally, create a key called `Governor` and assign the value to be your assigned state's governor. (See Module 2 - Dictionaries)\n",
        "1. Clean the transcript of irregularities.  This step is very open-ended.  Depending on the website, your transcript might not need any cleaning.  Examples of things to remove from the transcript include non-spoken content, like \"Applause\" or chanting from the audience.  Use your best judgment with this step.  Utilize regular expressions and the `replace` function. (Module 5 - Transcript Text Cleaning)\n",
        "1. Using TextBlob, find the subjectivity and polarity scores of the State of the State address.  In the `sots` dictionary, add the keys `Subjectivity` and `Polarity` with their scores being their respective TextBlob scores. You can assign the scores directly from the function calls or you can create variables, then assign those variables to the columns. (Module 5 - Sentiment Analysis with TextBlob)\n",
        "1. Use the TextStat module to obtain the syllable, word, and sentence count for the state of the state address.  Set the values to the respective `Syllables`, `Words`, and `Sentences` keys in the `sots` dictionary. You can assign the scores directly from the function calls or you can create variables, then assign those variables to the columns.(Module 5 - Text Statistics with TextStat)\n",
        "1. Using TextStat, obtain the Fleschâ€“Kincaid **grade**, Gunning Fog index, Automated Readability Index, Coleman-Liau Index, and Readability Consensus Score.  **When obtaining the Readability Consensus Score, be sure to use the `float_output=True` argument.**  Assign each of these scores to the following keys in `sots`: `FleschKincaid`, `Gunning`, `ARI`, `ColemanLiau`, and `RCS`. (Module 5 - Text Statistics with TextStat)\n",
        "1. From the Gensim package, use the keywords function to obtain the top 5 keywords present in the transcript.  **Use the `words=5`, `split=True` and `lemmatize=True` arguments.**  Assign each of keywords to a separate key in the `sots` dictionary.  The key names should be `Keyword1`, `Keyword2`, `Keyword3`, `Keyword4`, and `Keyword5`.  **Remember that Python starts counting at 0 when accessing the keywords list.** (Module 5 - Keyword Extraction)\n",
        "1. Convert the `sots` dictionary to a Pandas data frame using `df = pd.DataFrame(sots, index=[0])`.  With this code, the Pandas data frame is stored as a variable called `df`.  The `index=[0]` is just assigning all the values to the first row, since we are only creating a data frame with a single row.\n",
        "1. Create a CSV (comma separated value) file from the data frame made in the previous step.  **When calling the `to_csv` function, use the `index=False` argument.**  Name your CSV file after your state in title case (capitalize each word).  End the file name with the `.csv` file extension. For example, your file name would be \"Indiana.csv\".  (Module 4 - Exporting Data Frames as CSVs)\n",
        "1. Use a `return` statement to return your Pandas data frame called `df`.  This will allow for the tests cases to test out your function to ensure that all of the correct columns are being created.  \n",
        "\n",
        "Now you should be finished!  Your CSV file will contain a single row with the following columns:\n",
        "1. State\n",
        "1. Governor\n",
        "1. Subjectivity\n",
        "1. Polarity\n",
        "1. Syllables\n",
        "1. Words\n",
        "1. Sentences\n",
        "1. FleschKincaid\n",
        "1. Gunning\n",
        "1. ARI\n",
        "1. ColemanLiau\n",
        "1. RCS\n",
        "1. Keyword1\n",
        "1. Keyword2\n",
        "1. Keyword3\n",
        "1. Keyword4\n",
        "1. Keyword5\n",
        "\n",
        "To submit your work, download the .ipynb file and submit it to Gradescope.  Additionally, download the CSV file that you created (reference the module 4 project instructions).  You will submit this CSV via Brightspace.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ7XcVZyVDr0"
      },
      "source": [
        "You will type your code below in the `get_sots()` function.  All of the necessary modules have already been imported.  Make sure your are returning your Pandas data frame so that the test cases can test your code.  The test cases are only checking to make sure that your are creating the proper columns.  Look for the `OK` to make sure that your column names are correct.  Otherwise, it will tell you which test cases it is failing.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHY4-zfgVDr1"
      },
      "source": [
        "!pip install textstat\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "import textstat\n",
        "from gensim.summarization import keywords\n",
        "\n",
        "\n",
        "def get_sots():\n",
        "    # Type your code here\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "# IGNORE BELOW\n",
        "# Test Cases\n",
        "import unittest    \n",
        "    \n",
        "class TestCases(unittest.TestCase):\n",
        "    \n",
        "    global df\n",
        "    df = get_sots()\n",
        "    \n",
        "    def test_check_state_name(self):\n",
        "        self.assertTrue('State' in df.columns)\n",
        "        \n",
        "    def test_check_governor(self):\n",
        "        self.assertTrue('Governor' in df.columns)\n",
        "        \n",
        "    def test_check_polarity(self):\n",
        "        self.assertTrue('Polarity' in df.columns)\n",
        "        \n",
        "    def test_check_subjectivity(self):\n",
        "        self.assertTrue('Subjectivity' in df.columns)\n",
        "        \n",
        "    def test_check_syllables(self):\n",
        "        self.assertTrue('Syllables' in df.columns)\n",
        "        \n",
        "    def test_check_words(self):\n",
        "        self.assertTrue('Words' in df.columns)\n",
        "        \n",
        "    def test_check_flesch_kincaid(self):\n",
        "        self.assertTrue('FleschKincaid' in df.columns)\n",
        "        \n",
        "    def test_check_gunning(self):\n",
        "        self.assertTrue('Gunning' in df.columns)\n",
        "        \n",
        "    def test_check_ari(self):\n",
        "        self.assertTrue('ARI' in df.columns)\n",
        "        \n",
        "    def test_check_coleman_liau(self):\n",
        "        self.assertTrue('ColemanLiau' in df.columns)\n",
        "        \n",
        "    def test_check_rcs(self):\n",
        "        self.assertTrue('RCS' in df.columns)\n",
        "        \n",
        "    def test_check_keyword_1(self):\n",
        "        self.assertTrue('Keyword1' in df.columns)\n",
        "        \n",
        "    def test_check_keyword_2(self):\n",
        "        self.assertTrue('Keyword2' in df.columns)\n",
        "        \n",
        "    def test_check_keyword_3(self):\n",
        "        self.assertTrue('Keyword3' in df.columns)\n",
        "        \n",
        "    def test_check_keyword_4(self):\n",
        "        self.assertTrue('Keyword4' in df.columns)\n",
        "\n",
        "    def test_check_keyword_5(self):\n",
        "        self.assertTrue('Keyword5' in df.columns)\n",
        "        \n",
        "if __name__ == '__main__': \n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}